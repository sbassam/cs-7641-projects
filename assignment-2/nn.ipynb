{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import traitlets.utils.bunch\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from plotting import plot_learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_abalone_ternary():\n",
    "    df = pd.read_csv('data/abalone.data', names=[\"Sex\", \"Length\", \"Diameter\", \"Height\",\n",
    "                                                 \"Whole weight\", \"Shucked weight\", \"Viscera weight\",\n",
    "                                                 \"Shell weight\", \"Rings\"])\n",
    "    df = df[(df[\"Height\"] != 1.13) & (df['Height'] != 0.515)]\n",
    "\n",
    "    # deal with categorical data\n",
    "    df.loc[df.Sex == 'M', 'Male'] = 1.\n",
    "    df.loc[df.Sex == 'F', 'Female'] = 1.\n",
    "    df.loc[df.Sex == 'I', 'Infant'] = 1.\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # bucketize rings\n",
    "    df.loc[df.Rings < 11, 'Rings'] = 1.\n",
    "    df.loc[(df.Rings < 21) & (df.Rings > 10), 'Rings'] = 2.\n",
    "    df.loc[df.Rings > 20, 'Rings'] = 3.\n",
    "\n",
    "    return traitlets.Bunch(\n",
    "        data=df[['Male', 'Female', 'Infant', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
    "                 'Viscera weight', 'Shell weight']].values,\n",
    "        target=df[['Rings']].values,\n",
    "        target_names=df[\"Rings\"].unique(),\n",
    "        DESCR='abalone dataset...',\n",
    "        feature_names=['Male', 'Female', 'Infant', \"Length\", \"Diameter\", \"Height\",\n",
    "                       \"Whole weight\", \"Shucked weight\", \"Viscera weight\",\n",
    "                       \"Shell weight\"],\n",
    "    )\n",
    "\n",
    "abalone_ternary = process_abalone_ternary()\n",
    "ds_name = 'Abalone Ternary'\n",
    "\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(abalone_ternary.data,\n",
    "                                                                            abalone_ternary.target, test_size=0.3,\n",
    "                                                                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrose import NNGSRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running nngs_rhc\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "*****************\n",
      "*** Run START ***\n",
      "*****************\n",
      "max_iters:[100], restarts:[0], init_state:[[ 0.39293837 -0.42772133 -0.54629709  0.10262954  0.43893794 -0.15378708\n",
      "  0.9615284   0.36965948 -0.0381362  -0.21576496 -0.31364397  0.45809941\n",
      " -0.12285551 -0.88064421 -0.20391149]], algorithm:[rhc], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[1, 1]], learning_rate_init:[0.1], max_attempts:[10], current_restart:[0]\n",
      "runner_name:[nngs_rhc], experiment_name:[testesp], attempt:[0], iteration:[0], done:[False], time:[0.01], fitness:[1.1485]\n",
      "\t[ 0.39293837 -0.42772133 -0.54629709  0.10262954  0.43893794 -0.15378708//  0.9615284   0.36965948 -0.0381362  -0.21576496 -0.31364397  0.45809941// -0.12285551 -0.88064421 -0.20391149]...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iters:[100], restarts:[0], init_state:[[ 0.39293837 -0.42772133 -0.54629709  0.10262954  0.43893794 -0.15378708\n",
      "  0.9615284   0.36965948 -0.0381362  -0.21576496 -0.31364397  0.45809941\n",
      " -0.12285551 -0.88064421 -0.20391149]], algorithm:[rhc], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[1, 1]], learning_rate_init:[0.1], max_attempts:[10], current_restart:[0]\n",
      "runner_name:[nngs_rhc], experiment_name:[testesp], attempt:[11], iteration:[88], done:[True], time:[0.30], fitness:[1.0986]\n",
      "\t[ 0.19293837 -0.72772133 -0.74629709 -0.09737046  0.13893794 -0.15378708//  0.8615284   0.26965948 -0.1381362  -0.71576496 -0.41364397 -0.04190059// -0.02285551 -0.88064421 -0.60391149]...\n",
      "\n",
      "Saving: [out/TESTjupyter/testesp/nngs_rhc__testesp__run_stats_df__554BCA6D5A9A42AFA815EFBA804EED49.p]\n",
      "Saving: [out/TESTjupyter/testesp/nngs_rhc__testesp__run_stats_df__554BCA6D5A9A42AFA815EFBA804EED49.csv]\n",
      "Saving: [out/TESTjupyter/testesp/nngs_rhc__testesp__curves_df__554BCA6D5A9A42AFA815EFBA804EED49.p]\n",
      "Saving: [out/TESTjupyter/testesp/nngs_rhc__testesp__curves_df__554BCA6D5A9A42AFA815EFBA804EED49.csv]\n",
      "***************\n",
      "*** Run END ***\n",
      "***************\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1e9722246aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                   \u001b[0mgrid_search_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrhc_grid_search_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                   \u001b[0miteration_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16384\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                   seed=123)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-1e9722246aef>\u001b[0m in \u001b[0;36mrun_nn_experiment\u001b[0;34m(runner, output_directory, experiment_name, experiment_parameters, seed, grid_search_parameters, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mgrid_search_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_search_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutput_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                  **all_args).run()  \n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/omscs/cs-7641-ml/src/mlrose-hiive/mlrose/runners/_nn_runner_base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m                                            \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                            \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                                            verbose=self.verbose_grid_search)\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mrun_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Run time: {run_end - run_start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/omscs/cs-7641-ml/src/mlrose-hiive/mlrose/gridsearch/grid_search_mixin.py\u001b[0m in \u001b[0;36m_perform_grid_search\u001b[0;34m(self, classifier, x_train, y_train, cv, parameters, n_jobs, verbose)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                            \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                            verbose=verbose)\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msearch_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \"\"\"\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 97\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/omscs/cs-7641-ml/src/mlrose-hiive/mlrose/runners/_nn_runner_base.py\u001b[0m in \u001b[0;36m_grid_search_score_intercept\u001b[0;34m(self, y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                                     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                                     \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                                     adjusted=adjusted)\n\u001b[0m",
      "\u001b[0;32m~/Documents/omscs/cs-7641-ml/src/mlrose-hiive/mlrose/gridsearch/grid_search_mixin.py\u001b[0m in \u001b[0;36m_grid_search_score_intercept\u001b[0;34m(self, y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_grid_search_score_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjusted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGridSearchMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scorer_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjusted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mbalanced_accuracy_score\u001b[0;34m(y_true, y_pred, sample_weight, adjusted)\u001b[0m\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m     \"\"\"\n\u001b[0;32m-> 1741\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "rhc_grid_search_params = {\n",
    "    'restarts': [0],\n",
    "    'max_iters': [100],\n",
    "    'learning_rate_init': [0.1],\n",
    "    'hidden_layer_sizes': [[1, 1]],\n",
    "    'activation': [mlrose.neural.activation.relu],\n",
    "}\n",
    "rhc_experiment_parameters = {\n",
    "    'x_train': features_train,\n",
    "    'y_train': labels_train_hot,\n",
    "    'x_test': features_test,\n",
    "    'y_test': labels_test_hot,\n",
    "    'max_attempts': 10,\n",
    "    'early_stopping': True\n",
    "}\n",
    "\n",
    "\n",
    "def run_nn_experiment(runner, output_directory, experiment_name, experiment_parameters, seed, grid_search_parameters, **kwargs):\n",
    "    all_args = {**experiment_parameters,**kwargs,}\n",
    "    results = runner(seed=seed, \n",
    "            experiment_name=experiment_name, \n",
    "            grid_search_parameters=grid_search_parameters,\n",
    "            output_directory=output_directory,\n",
    "                 **all_args).run()  \n",
    "    \n",
    "    print(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "run_nn_experiment(runner=NNGSRunner,\n",
    "                  algorithm=mlrose.algorithms.rhc.random_hill_climb,\n",
    "                  output_directory='out/TESTjupyter',\n",
    "                  experiment_name='testesp',\n",
    "                  experiment_parameters=rhc_experiment_parameters,\n",
    "                  grid_search_parameters=rhc_grid_search_params,\n",
    "                  iteration_list=[2048, 4096, 8192, 16384],\n",
    "                  seed=123)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    " \n",
    "# https://mlrose.readthedocs.io/en/stable/source/tutorial3.html\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "labels_train_hot = one_hot.fit_transform(labels_train.reshape(-1, 1)).todense()\n",
    "labels_test_hot = one_hot.transform(labels_test.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, \\\n",
    "                                                    test_size = 0.2, random_state = 3)\n",
    "\n",
    "# # Normalize feature data\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # One hot encode target values\n",
    "# one_hot = OneHotEncoder()\n",
    "\n",
    "# y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "# y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.    , 0.    , ..., 0.2245, 0.101 , 0.15  ],\n",
       "       [1.    , 0.    , 0.    , ..., 0.0995, 0.0485, 0.07  ],\n",
       "       [0.    , 1.    , 0.    , ..., 0.2565, 0.1415, 0.21  ],\n",
       "       ...,\n",
       "       [1.    , 0.    , 0.    , ..., 0.5255, 0.2875, 0.308 ],\n",
       "       [0.    , 1.    , 0.    , ..., 0.531 , 0.261 , 0.296 ],\n",
       "       [1.    , 0.    , 0.    , ..., 0.9455, 0.3765, 0.495 ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_ternary.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 0, 1, 2, 1, 0, 0,\n",
       "       2, 1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 1, 0, 0, 1, 2, 2, 0, 2, 1, 0, 0,\n",
       "       2, 2, 2, 1, 1, 1, 0, 0, 2, 2, 1, 2, 1, 2, 0, 2, 0, 1, 1, 2, 2, 0,\n",
       "       1, 0, 1, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 1, 2, 1, 0, 1, 2,\n",
       "       0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 1,\n",
       "       1, 0, 1, 2, 2, 2, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 2, 0, 1, 2, 2, 0, 2, 2,\n",
       "       2, 1, 0, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target[:88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[:88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_restarts</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.077148</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>relu</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0       0.077148      0.004316         0.001685        0.000184   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes  param_learning_rate_init  \\\n",
       "0             relu                   [1, 1]                       0.1   \n",
       "\n",
       "   param_max_iters  param_restarts  ... mean_test_score  std_test_score  \\\n",
       "0             1000               0  ...         0.64491        0.012926   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1             0.63997            0.647829   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.645584            0.648578             0.64259   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0           0.64491         0.003232  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/TESTjupyters/testesp/nngs_gd__testesp__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44.938453</td>\n",
       "      <td>1.098109</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>relu</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>236.618305</td>\n",
       "      <td>19.539702</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>relu</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>410.808210</td>\n",
       "      <td>1.794451</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>relu</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>43.203220</td>\n",
       "      <td>1.616083</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>207.378474</td>\n",
       "      <td>1.926149</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>412.001902</td>\n",
       "      <td>0.638592</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.63997</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.64259</td>\n",
       "      <td>0.64491</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0      44.938453      1.098109         0.001338        0.000307   \n",
       "1           1     236.618305     19.539702         0.001299        0.000207   \n",
       "2           2     410.808210      1.794451         0.001211        0.000026   \n",
       "3           3      43.203220      1.616083         0.001153        0.000028   \n",
       "4           4     207.378474      1.926149         0.001213        0.000021   \n",
       "5           5     412.001902      0.638592         0.001272        0.000048   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes  param_learning_rate_init  \\\n",
       "0             relu                [1, 1, 1]                      0.01   \n",
       "1             relu                [1, 1, 1]                      0.01   \n",
       "2             relu                [1, 1, 1]                      0.01   \n",
       "3             relu                [2, 2, 2]                      0.01   \n",
       "4             relu                [2, 2, 2]                      0.01   \n",
       "5             relu                [2, 2, 2]                      0.01   \n",
       "\n",
       "   param_max_iters  param_temperature  ... mean_test_score  std_test_score  \\\n",
       "0              100                  1  ...         0.64491        0.012926   \n",
       "1              500                  1  ...         0.64491        0.012926   \n",
       "2             1000                  1  ...         0.64491        0.012926   \n",
       "3              100                  1  ...         0.64491        0.012926   \n",
       "4              500                  1  ...         0.64491        0.012926   \n",
       "5             1000                  1  ...         0.64491        0.012926   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1             0.63997            0.647829   \n",
       "1                1             0.63997            0.647829   \n",
       "2                1             0.63997            0.647829   \n",
       "3                1             0.63997            0.647829   \n",
       "4                1             0.63997            0.647829   \n",
       "5                1             0.63997            0.647829   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.645584            0.648578             0.64259   \n",
       "1            0.645584            0.648578             0.64259   \n",
       "2            0.645584            0.648578             0.64259   \n",
       "3            0.645584            0.648578             0.64259   \n",
       "4            0.645584            0.648578             0.64259   \n",
       "5            0.645584            0.648578             0.64259   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0           0.64491         0.003232  \n",
       "1           0.64491         0.003232  \n",
       "2           0.64491         0.003232  \n",
       "3           0.64491         0.003232  \n",
       "4           0.64491         0.003232  \n",
       "5           0.64491         0.003232  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/newss/testgdss/nngs_ga__testgdss__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904191616766467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "Iris = load_iris()\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(abalone_ternary.data, abalone_ternary.target, \\\n",
    "                                                    test_size = 0.2, random_state = 31)\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()\n",
    "# Initialize neural network object and fit object\n",
    "nn_model1 = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \\\n",
    "                                 algorithm = 'genetic_alg', max_iters = 20000, \\\n",
    "                                 bias = True, is_classifier = True, learning_rate = 0.0001, \\\n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 10000, \\\n",
    "                                 random_state = 3)\n",
    "\n",
    "nn_model1.fit(X_train_scaled, y_train_hot)\n",
    "y_test_pred = nn_model1.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "print(y_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517964071856287\n",
      "0.6598802395209581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = nn_model1.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(y_train_accuracy)\n",
    "\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = nn_model1.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "print(y_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(100, 1000, 100):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Time</th>\n",
       "      <th>State</th>\n",
       "      <th>max_iters</th>\n",
       "      <th>temperature</th>\n",
       "      <th>init_state</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>activation</th>\n",
       "      <th>bias</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>clip_max</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>max_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.009895</td>\n",
       "      <td>0.065042</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>27.010806</td>\n",
       "      <td>13.860455</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>27.010806</td>\n",
       "      <td>13.860455</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>27.010806</td>\n",
       "      <td>13.860455</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2048</td>\n",
       "      <td>27.010806</td>\n",
       "      <td>13.860455</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>4096</td>\n",
       "      <td>27.010806</td>\n",
       "      <td>13.860455</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8192</td>\n",
       "      <td>27.010806</td>\n",
       "      <td>13.860455</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5640231754284875, -0.8564369369171607, 0.6...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[300, 300, 300, 300]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Iteration    Fitness       Time  \\\n",
       "0           0          0  27.009895   0.065042   \n",
       "1           1        256  27.010806  13.860455   \n",
       "2           2        512  27.010806  13.860455   \n",
       "3           3       1024  27.010806  13.860455   \n",
       "4           4       2048  27.010806  13.860455   \n",
       "5           5       4096  27.010806  13.860455   \n",
       "6           6       8192  27.010806  13.860455   \n",
       "\n",
       "                                               State  max_iters  temperature  \\\n",
       "0  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "1  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "2  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "3  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "4  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "5  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "6  [-0.5640231754284875, -0.8564369369171607, 0.6...        100            1   \n",
       "\n",
       "                                          init_state algorithm activation  \\\n",
       "0  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "1  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "2  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "3  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "4  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "5  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "6  [-0.5640231754284875, -0.8564369369171607, 0.6...        sa       relu   \n",
       "\n",
       "   bias  early_stopping      clip_max    hidden_layer_sizes  \\\n",
       "0  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "1  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "2  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "3  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "4  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "5  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "6  True            True  1.000000e+10  [300, 300, 300, 300]   \n",
       "\n",
       "   learning_rate_init  max_attempts  \n",
       "0               0.001          1000  \n",
       "1               0.001          1000  \n",
       "2               0.001          1000  \n",
       "3               0.001          1000  \n",
       "4               0.001          1000  \n",
       "5               0.001          1000  \n",
       "6               0.001          1000  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/tuning/nngs_sa__tuning__run_stats_df__5CD4E7D8819FA62F2B20E949C7269555.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.746462</td>\n",
       "      <td>0.167307</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>relu</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298204</td>\n",
       "      <td>0.220477</td>\n",
       "      <td>4</td>\n",
       "      <td>0.646707</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.123129</td>\n",
       "      <td>0.299401</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.217055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.806125</td>\n",
       "      <td>0.231238</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>relu</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350898</td>\n",
       "      <td>0.037748</td>\n",
       "      <td>2</td>\n",
       "      <td>0.319985</td>\n",
       "      <td>0.307635</td>\n",
       "      <td>0.405689</td>\n",
       "      <td>0.346931</td>\n",
       "      <td>0.401946</td>\n",
       "      <td>0.356437</td>\n",
       "      <td>0.040737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.731359</td>\n",
       "      <td>0.178644</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>relu</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314970</td>\n",
       "      <td>0.070912</td>\n",
       "      <td>3</td>\n",
       "      <td>0.356287</td>\n",
       "      <td>0.409431</td>\n",
       "      <td>0.389222</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.325075</td>\n",
       "      <td>0.078972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.542188</td>\n",
       "      <td>0.129054</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>relu</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506886</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639970</td>\n",
       "      <td>0.651572</td>\n",
       "      <td>0.441991</td>\n",
       "      <td>0.191991</td>\n",
       "      <td>0.598428</td>\n",
       "      <td>0.504790</td>\n",
       "      <td>0.173421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0       5.746462      0.167307         0.001619        0.000376   \n",
       "1           1       5.806125      0.231238         0.001663        0.000271   \n",
       "2           2       5.731359      0.178644         0.001489        0.000039   \n",
       "3           3       5.542188      0.129054         0.001678        0.000502   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes  param_learning_rate_init  \\\n",
       "0             relu             [5, 5, 5, 5]                     0.001   \n",
       "1             relu             [5, 5, 5, 5]                     0.001   \n",
       "2             relu             [5, 5, 5, 5]                     0.001   \n",
       "3             relu             [5, 5, 5, 5]                     0.001   \n",
       "\n",
       "   param_max_iters  param_temperature  ... mean_test_score  std_test_score  \\\n",
       "0             1000                  1  ...        0.298204        0.220477   \n",
       "1             1000                  5  ...        0.350898        0.037748   \n",
       "2             1000                 10  ...        0.314970        0.070912   \n",
       "3             1000                 20  ...        0.506886        0.185355   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                4            0.646707            0.327470   \n",
       "1                2            0.319985            0.307635   \n",
       "2                3            0.356287            0.409431   \n",
       "3                1            0.639970            0.651572   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.008234            0.123129            0.299401   \n",
       "1            0.405689            0.346931            0.401946   \n",
       "2            0.389222            0.197605            0.272829   \n",
       "3            0.441991            0.191991            0.598428   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.280988         0.217055  \n",
       "1          0.356437         0.040737  \n",
       "2          0.325075         0.078972  \n",
       "3          0.504790         0.173421  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/tuning/nngs_sa__tuning__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Time</th>\n",
       "      <th>State</th>\n",
       "      <th>max_iters</th>\n",
       "      <th>temperature</th>\n",
       "      <th>init_state</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>activation</th>\n",
       "      <th>bias</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>clip_max</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>max_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996958</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>[0.582027428001004, -0.7480828712261727, -0.32...</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.582027428001004, -0.7480828712261727, -0.32...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.998062</td>\n",
       "      <td>6.416772</td>\n",
       "      <td>[0.583027428001004, -0.7510828712261727, -0.32...</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.582027428001004, -0.7480828712261727, -0.32...</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Iteration   Fitness      Time  \\\n",
       "0           0          0  0.996958  0.003883   \n",
       "1           1       1000  0.998062  6.416772   \n",
       "\n",
       "                                               State  max_iters  temperature  \\\n",
       "0  [0.582027428001004, -0.7480828712261727, -0.32...       1000           20   \n",
       "1  [0.583027428001004, -0.7510828712261727, -0.32...       1000           20   \n",
       "\n",
       "                                          init_state algorithm activation  \\\n",
       "0  [0.582027428001004, -0.7480828712261727, -0.32...        sa       relu   \n",
       "1  [0.582027428001004, -0.7480828712261727, -0.32...        sa       relu   \n",
       "\n",
       "   bias  early_stopping      clip_max hidden_layer_sizes  learning_rate_init  \\\n",
       "0  True            True  1.000000e+10       [5, 5, 5, 5]               0.001   \n",
       "1  True            True  1.000000e+10       [5, 5, 5, 5]               0.001   \n",
       "\n",
       "   max_attempts  \n",
       "0          1000  \n",
       "1          1000  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/tuning/nngs_sa__tuning__run_stats_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlrose\n",
    "import numpy as np\n",
    "fitness = mlrose.FlipFlop()\n",
    "state = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
    "fitness.evaluate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'mean_fit_time', 'std_fit_time', 'mean_score_time',\n",
       "       'std_score_time', 'param_activation', 'param_hidden_layer_sizes',\n",
       "       'param_learning_rate_init', 'param_max_iters', 'param_temperature',\n",
       "       'params', 'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/tuning/nngs_sa__tuning__cv_results_df.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Time</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>max_iters</th>\n",
       "      <th>temperature</th>\n",
       "      <th>init_state</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>activation</th>\n",
       "      <th>bias</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>clip_max</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>max_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>1.007666</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>1.007666</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>1.007657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.026344</td>\n",
       "      <td>1.007657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032358</td>\n",
       "      <td>1.007657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038501</td>\n",
       "      <td>1.007692</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.045089</td>\n",
       "      <td>1.007692</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.051408</td>\n",
       "      <td>1.007678</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>1.007680</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>1.007682</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.069619</td>\n",
       "      <td>1.007683</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.075762</td>\n",
       "      <td>1.007683</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.082001</td>\n",
       "      <td>1.007683</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.087907</td>\n",
       "      <td>1.007684</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.094011</td>\n",
       "      <td>1.007688</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.100325</td>\n",
       "      <td>1.007688</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.106437</td>\n",
       "      <td>1.007687</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.112509</td>\n",
       "      <td>1.007692</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>1.007704</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.125920</td>\n",
       "      <td>1.007716</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.134091</td>\n",
       "      <td>1.007716</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0.140453</td>\n",
       "      <td>1.007714</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.147310</td>\n",
       "      <td>1.007714</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.153537</td>\n",
       "      <td>1.007690</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.160410</td>\n",
       "      <td>1.007684</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.166612</td>\n",
       "      <td>1.007686</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.174727</td>\n",
       "      <td>1.007686</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0.181438</td>\n",
       "      <td>1.007679</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0.187504</td>\n",
       "      <td>1.007670</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.195093</td>\n",
       "      <td>1.007671</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>6.414407</td>\n",
       "      <td>1.007064</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>971</td>\n",
       "      <td>6.421708</td>\n",
       "      <td>1.007078</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>972</td>\n",
       "      <td>6.429218</td>\n",
       "      <td>1.007078</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>973</td>\n",
       "      <td>6.435383</td>\n",
       "      <td>1.007073</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "      <td>6.442380</td>\n",
       "      <td>1.007073</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>6.448727</td>\n",
       "      <td>1.007070</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>976</td>\n",
       "      <td>976</td>\n",
       "      <td>6.455121</td>\n",
       "      <td>1.007070</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>977</td>\n",
       "      <td>977</td>\n",
       "      <td>6.461934</td>\n",
       "      <td>1.007035</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>978</td>\n",
       "      <td>6.468218</td>\n",
       "      <td>1.007032</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>979</td>\n",
       "      <td>979</td>\n",
       "      <td>6.475015</td>\n",
       "      <td>1.007032</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>6.481225</td>\n",
       "      <td>1.007040</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "      <td>6.487419</td>\n",
       "      <td>1.007075</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>982</td>\n",
       "      <td>982</td>\n",
       "      <td>6.494249</td>\n",
       "      <td>1.007075</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>983</td>\n",
       "      <td>983</td>\n",
       "      <td>6.500369</td>\n",
       "      <td>1.007073</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>984</td>\n",
       "      <td>984</td>\n",
       "      <td>6.506938</td>\n",
       "      <td>1.007073</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>6.513181</td>\n",
       "      <td>1.007067</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>6.519267</td>\n",
       "      <td>1.007067</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>987</td>\n",
       "      <td>987</td>\n",
       "      <td>6.526278</td>\n",
       "      <td>1.007059</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>6.532276</td>\n",
       "      <td>1.007066</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>6.538201</td>\n",
       "      <td>1.007073</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>6.546490</td>\n",
       "      <td>1.007067</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>991</td>\n",
       "      <td>991</td>\n",
       "      <td>6.552862</td>\n",
       "      <td>1.007058</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>992</td>\n",
       "      <td>992</td>\n",
       "      <td>6.559736</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>993</td>\n",
       "      <td>6.565807</td>\n",
       "      <td>1.007117</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>994</td>\n",
       "      <td>6.571632</td>\n",
       "      <td>1.007107</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>6.578782</td>\n",
       "      <td>1.007141</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>6.584654</td>\n",
       "      <td>1.007194</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>6.591120</td>\n",
       "      <td>1.007196</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>6.597970</td>\n",
       "      <td>1.007195</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>6.603851</td>\n",
       "      <td>1.007198</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.25359335510448244, -0.3100382457826272, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Iteration      Time   Fitness  max_iters  temperature  \\\n",
       "0             0          0  0.004541  1.007666       1000            1   \n",
       "1             1          1  0.013797  1.007666       1000            1   \n",
       "2             2          2  0.020040  1.007657       1000            1   \n",
       "3             3          3  0.026344  1.007657       1000            1   \n",
       "4             4          4  0.032358  1.007657       1000            1   \n",
       "5             5          5  0.038501  1.007692       1000            1   \n",
       "6             6          6  0.045089  1.007692       1000            1   \n",
       "7             7          7  0.051408  1.007678       1000            1   \n",
       "8             8          8  0.057585  1.007680       1000            1   \n",
       "9             9          9  0.063436  1.007682       1000            1   \n",
       "10           10         10  0.069619  1.007683       1000            1   \n",
       "11           11         11  0.075762  1.007683       1000            1   \n",
       "12           12         12  0.082001  1.007683       1000            1   \n",
       "13           13         13  0.087907  1.007684       1000            1   \n",
       "14           14         14  0.094011  1.007688       1000            1   \n",
       "15           15         15  0.100325  1.007688       1000            1   \n",
       "16           16         16  0.106437  1.007687       1000            1   \n",
       "17           17         17  0.112509  1.007692       1000            1   \n",
       "18           18         18  0.119205  1.007704       1000            1   \n",
       "19           19         19  0.125920  1.007716       1000            1   \n",
       "20           20         20  0.134091  1.007716       1000            1   \n",
       "21           21         21  0.140453  1.007714       1000            1   \n",
       "22           22         22  0.147310  1.007714       1000            1   \n",
       "23           23         23  0.153537  1.007690       1000            1   \n",
       "24           24         24  0.160410  1.007684       1000            1   \n",
       "25           25         25  0.166612  1.007686       1000            1   \n",
       "26           26         26  0.174727  1.007686       1000            1   \n",
       "27           27         27  0.181438  1.007679       1000            1   \n",
       "28           28         28  0.187504  1.007670       1000            1   \n",
       "29           29         29  0.195093  1.007671       1000            1   \n",
       "..          ...        ...       ...       ...        ...          ...   \n",
       "970         970        970  6.414407  1.007064       1000            1   \n",
       "971         971        971  6.421708  1.007078       1000            1   \n",
       "972         972        972  6.429218  1.007078       1000            1   \n",
       "973         973        973  6.435383  1.007073       1000            1   \n",
       "974         974        974  6.442380  1.007073       1000            1   \n",
       "975         975        975  6.448727  1.007070       1000            1   \n",
       "976         976        976  6.455121  1.007070       1000            1   \n",
       "977         977        977  6.461934  1.007035       1000            1   \n",
       "978         978        978  6.468218  1.007032       1000            1   \n",
       "979         979        979  6.475015  1.007032       1000            1   \n",
       "980         980        980  6.481225  1.007040       1000            1   \n",
       "981         981        981  6.487419  1.007075       1000            1   \n",
       "982         982        982  6.494249  1.007075       1000            1   \n",
       "983         983        983  6.500369  1.007073       1000            1   \n",
       "984         984        984  6.506938  1.007073       1000            1   \n",
       "985         985        985  6.513181  1.007067       1000            1   \n",
       "986         986        986  6.519267  1.007067       1000            1   \n",
       "987         987        987  6.526278  1.007059       1000            1   \n",
       "988         988        988  6.532276  1.007066       1000            1   \n",
       "989         989        989  6.538201  1.007073       1000            1   \n",
       "990         990        990  6.546490  1.007067       1000            1   \n",
       "991         991        991  6.552862  1.007058       1000            1   \n",
       "992         992        992  6.559736  1.007116       1000            1   \n",
       "993         993        993  6.565807  1.007117       1000            1   \n",
       "994         994        994  6.571632  1.007107       1000            1   \n",
       "995         995        995  6.578782  1.007141       1000            1   \n",
       "996         996        996  6.584654  1.007194       1000            1   \n",
       "997         997        997  6.591120  1.007196       1000            1   \n",
       "998         998        998  6.597970  1.007195       1000            1   \n",
       "999         999        999  6.603851  1.007198       1000            1   \n",
       "\n",
       "                                            init_state algorithm activation  \\\n",
       "0    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "1    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "2    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "3    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "4    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "5    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "6    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "7    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "8    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "9    [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "10   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "11   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "12   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "13   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "14   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "15   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "16   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "17   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "18   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "19   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "20   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "21   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "22   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "23   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "24   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "25   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "26   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "27   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "28   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "29   [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "..                                                 ...       ...        ...   \n",
       "970  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "971  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "972  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "973  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "974  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "975  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "976  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "977  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "978  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "979  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "980  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "981  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "982  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "983  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "984  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "985  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "986  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "987  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "988  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "989  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "990  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "991  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "992  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "993  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "994  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "995  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "996  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "997  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "998  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "999  [-0.25359335510448244, -0.3100382457826272, 0....        sa       relu   \n",
       "\n",
       "     bias  early_stopping      clip_max hidden_layer_sizes  \\\n",
       "0    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "1    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "2    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "3    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "4    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "5    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "6    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "7    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "8    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "9    True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "10   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "11   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "12   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "13   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "14   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "15   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "16   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "17   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "18   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "19   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "20   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "21   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "22   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "23   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "24   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "25   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "26   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "27   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "28   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "29   True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "..    ...             ...           ...                ...   \n",
       "970  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "971  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "972  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "973  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "974  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "975  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "976  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "977  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "978  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "979  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "980  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "981  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "982  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "983  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "984  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "985  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "986  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "987  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "988  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "989  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "990  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "991  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "992  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "993  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "994  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "995  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "996  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "997  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "998  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "999  True            True  1.000000e+10       [5, 5, 5, 5]   \n",
       "\n",
       "     learning_rate_init  max_attempts  \n",
       "0                 0.001          1000  \n",
       "1                 0.001          1000  \n",
       "2                 0.001          1000  \n",
       "3                 0.001          1000  \n",
       "4                 0.001          1000  \n",
       "5                 0.001          1000  \n",
       "6                 0.001          1000  \n",
       "7                 0.001          1000  \n",
       "8                 0.001          1000  \n",
       "9                 0.001          1000  \n",
       "10                0.001          1000  \n",
       "11                0.001          1000  \n",
       "12                0.001          1000  \n",
       "13                0.001          1000  \n",
       "14                0.001          1000  \n",
       "15                0.001          1000  \n",
       "16                0.001          1000  \n",
       "17                0.001          1000  \n",
       "18                0.001          1000  \n",
       "19                0.001          1000  \n",
       "20                0.001          1000  \n",
       "21                0.001          1000  \n",
       "22                0.001          1000  \n",
       "23                0.001          1000  \n",
       "24                0.001          1000  \n",
       "25                0.001          1000  \n",
       "26                0.001          1000  \n",
       "27                0.001          1000  \n",
       "28                0.001          1000  \n",
       "29                0.001          1000  \n",
       "..                  ...           ...  \n",
       "970               0.001          1000  \n",
       "971               0.001          1000  \n",
       "972               0.001          1000  \n",
       "973               0.001          1000  \n",
       "974               0.001          1000  \n",
       "975               0.001          1000  \n",
       "976               0.001          1000  \n",
       "977               0.001          1000  \n",
       "978               0.001          1000  \n",
       "979               0.001          1000  \n",
       "980               0.001          1000  \n",
       "981               0.001          1000  \n",
       "982               0.001          1000  \n",
       "983               0.001          1000  \n",
       "984               0.001          1000  \n",
       "985               0.001          1000  \n",
       "986               0.001          1000  \n",
       "987               0.001          1000  \n",
       "988               0.001          1000  \n",
       "989               0.001          1000  \n",
       "990               0.001          1000  \n",
       "991               0.001          1000  \n",
       "992               0.001          1000  \n",
       "993               0.001          1000  \n",
       "994               0.001          1000  \n",
       "995               0.001          1000  \n",
       "996               0.001          1000  \n",
       "997               0.001          1000  \n",
       "998               0.001          1000  \n",
       "999               0.001          1000  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/tuning/nngs_sa__tuning__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_temperature</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.071365</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.179641</td>\n",
       "      <td>0.426647</td>\n",
       "      <td>0.642216</td>\n",
       "      <td>0.663174</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>0.444611</td>\n",
       "      <td>0.187137</td>\n",
       "      <td>4</td>\n",
       "      <td>0.176272</td>\n",
       "      <td>0.483159</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.661302</td>\n",
       "      <td>0.341692</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.184383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.092925</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.440120</td>\n",
       "      <td>0.559880</td>\n",
       "      <td>0.624251</td>\n",
       "      <td>0.613772</td>\n",
       "      <td>0.619760</td>\n",
       "      <td>0.571557</td>\n",
       "      <td>0.069706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403817</td>\n",
       "      <td>0.599177</td>\n",
       "      <td>0.605913</td>\n",
       "      <td>0.585704</td>\n",
       "      <td>0.607036</td>\n",
       "      <td>0.560329</td>\n",
       "      <td>0.078624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.127856</td>\n",
       "      <td>0.015213</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.348802</td>\n",
       "      <td>0.419162</td>\n",
       "      <td>0.321856</td>\n",
       "      <td>0.354790</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.352395</td>\n",
       "      <td>0.036431</td>\n",
       "      <td>5</td>\n",
       "      <td>0.334955</td>\n",
       "      <td>0.374251</td>\n",
       "      <td>0.351048</td>\n",
       "      <td>0.342814</td>\n",
       "      <td>0.352171</td>\n",
       "      <td>0.351048</td>\n",
       "      <td>0.013164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.365269</td>\n",
       "      <td>0.308383</td>\n",
       "      <td>0.272455</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.245509</td>\n",
       "      <td>0.294611</td>\n",
       "      <td>0.040639</td>\n",
       "      <td>6</td>\n",
       "      <td>0.340195</td>\n",
       "      <td>0.269461</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>0.276198</td>\n",
       "      <td>0.285180</td>\n",
       "      <td>0.289895</td>\n",
       "      <td>0.025646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.200657</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>0.386228</td>\n",
       "      <td>0.642216</td>\n",
       "      <td>0.630240</td>\n",
       "      <td>0.631737</td>\n",
       "      <td>0.513772</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>2</td>\n",
       "      <td>0.276946</td>\n",
       "      <td>0.349551</td>\n",
       "      <td>0.645584</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.627246</td>\n",
       "      <td>0.509581</td>\n",
       "      <td>0.162105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.241485</td>\n",
       "      <td>0.018492</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.633234</td>\n",
       "      <td>0.226048</td>\n",
       "      <td>0.585329</td>\n",
       "      <td>0.631737</td>\n",
       "      <td>0.450599</td>\n",
       "      <td>0.204837</td>\n",
       "      <td>3</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.235404</td>\n",
       "      <td>0.592066</td>\n",
       "      <td>0.627246</td>\n",
       "      <td>0.454865</td>\n",
       "      <td>0.206917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.255069</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>relu</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': &lt;function relu at 0x10c4e1cb0&gt;,...</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.339820</td>\n",
       "      <td>0.254491</td>\n",
       "      <td>0.184132</td>\n",
       "      <td>0.429641</td>\n",
       "      <td>0.288323</td>\n",
       "      <td>0.086747</td>\n",
       "      <td>7</td>\n",
       "      <td>0.223054</td>\n",
       "      <td>0.324850</td>\n",
       "      <td>0.269461</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>0.397829</td>\n",
       "      <td>0.277395</td>\n",
       "      <td>0.078647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time param_activation param_hidden_layer_sizes  param_learning_rate_init  param_max_iters  param_temperature                                             params  split0_test_score  split1_test_score  split2_test_score  split3_test_score  split4_test_score  mean_test_score  std_test_score  rank_test_score  split0_train_score  split1_train_score  split2_train_score  split3_train_score  split4_train_score  mean_train_score  std_train_score\n",
       "0           0       0.071365      0.015640         0.001751        0.000885             relu                      [2]                     0.001               10                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.179641           0.426647           0.642216           0.663174           0.311377         0.444611        0.187137                4            0.176272            0.483159            0.645584            0.661302            0.341692          0.461602         0.184383\n",
       "1           1       0.092925      0.008848         0.001321        0.000169             relu                      [2]                     0.001               15                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.440120           0.559880           0.624251           0.613772           0.619760         0.571557        0.069706                1            0.403817            0.599177            0.605913            0.585704            0.607036          0.560329         0.078624\n",
       "2           2       0.127856      0.015213         0.001227        0.000072             relu                      [2]                     0.001               20                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.348802           0.419162           0.321856           0.354790           0.317365         0.352395        0.036431                5            0.334955            0.374251            0.351048            0.342814            0.352171          0.351048         0.013164\n",
       "3           3       0.156417      0.004944         0.001305        0.000061             relu                      [2]                     0.001               25                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.365269           0.308383           0.272455           0.281437           0.245509         0.294611        0.040639                6            0.340195            0.269461            0.278443            0.276198            0.285180          0.289895         0.025646\n",
       "4           4       0.200657      0.015674         0.001429        0.000144             relu                      [2]                     0.001               30                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.278443           0.386228           0.642216           0.630240           0.631737         0.513772        0.152069                2            0.276946            0.349551            0.645584            0.648578            0.627246          0.509581         0.162105\n",
       "5           5       0.241485      0.018492         0.001559        0.000272             relu                      [2]                     0.001               35                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.176647           0.633234           0.226048           0.585329           0.631737         0.450599        0.204837                3            0.171781            0.647829            0.235404            0.592066            0.627246          0.454865         0.206917\n",
       "6           6       0.255069      0.005367         0.001229        0.000073             relu                      [2]                     0.001               40                  1  {'activation': <function relu at 0x10c4e1cb0>,...           0.233533           0.339820           0.254491           0.184132           0.429641         0.288323        0.086747                7            0.223054            0.324850            0.269461            0.171781            0.397829          0.277395         0.078647"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.read_csv('out/sa/iters/nngs_sa__iters__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Time</th>\n",
       "      <th>State</th>\n",
       "      <th>max_iters</th>\n",
       "      <th>temperature</th>\n",
       "      <th>init_state</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>activation</th>\n",
       "      <th>bias</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>clip_max</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>max_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>[0.005915312314872523, -0.9787721710528132, 0....</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.005915312314872523, -0.9787721710528132, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.094759</td>\n",
       "      <td>[0.008915312314872522, -0.9807721710528132, 0....</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.005915312314872523, -0.9787721710528132, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.094759</td>\n",
       "      <td>[0.008915312314872522, -0.9807721710528132, 0....</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.005915312314872523, -0.9787721710528132, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.094759</td>\n",
       "      <td>[0.008915312314872522, -0.9807721710528132, 0....</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.005915312314872523, -0.9787721710528132, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>5.094759</td>\n",
       "      <td>[0.008915312314872522, -0.9807721710528132, 0....</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.005915312314872523, -0.9787721710528132, 0....</td>\n",
       "      <td>sa</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Iteration   Fitness      Time                                              State  max_iters  temperature                                         init_state algorithm activation  bias  early_stopping      clip_max hidden_layer_sizes  learning_rate_init  max_attempts\n",
       "0           0          0  1.098612  0.002718  [0.005915312314872523, -0.9787721710528132, 0....       1000            1  [0.005915312314872523, -0.9787721710528132, 0....        sa       relu  True            True  1.000000e+10             [2, 2]               0.001          1000\n",
       "1           1       1000  1.098612  5.094759  [0.008915312314872522, -0.9807721710528132, 0....       1000            1  [0.005915312314872523, -0.9787721710528132, 0....        sa       relu  True            True  1.000000e+10             [2, 2]               0.001          1000\n",
       "2           2       2000  1.098612  5.094759  [0.008915312314872522, -0.9807721710528132, 0....       1000            1  [0.005915312314872523, -0.9787721710528132, 0....        sa       relu  True            True  1.000000e+10             [2, 2]               0.001          1000\n",
       "3           3       5000  1.098612  5.094759  [0.008915312314872522, -0.9807721710528132, 0....       1000            1  [0.005915312314872523, -0.9787721710528132, 0....        sa       relu  True            True  1.000000e+10             [2, 2]               0.001          1000\n",
       "4           4      10000  1.098612  5.094759  [0.008915312314872522, -0.9807721710528132, 0....       1000            1  [0.005915312314872523, -0.9787721710528132, 0....        sa       relu  True            True  1.000000e+10             [2, 2]               0.001          1000"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/iters/nngs_sa__iters__run_stats_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_temperature</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x1183fecb0&gt;,...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.092796</td>\n",
       "      <td>3</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.320833</td>\n",
       "      <td>0.101508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.873508</td>\n",
       "      <td>0.054728</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x1183fecb0&gt;,...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.137941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>0.137468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.800541</td>\n",
       "      <td>0.095453</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>900</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x1183fecb0&gt;,...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.123603</td>\n",
       "      <td>4</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.268750</td>\n",
       "      <td>0.134436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.011549</td>\n",
       "      <td>0.048112</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': &lt;function relu at 0x1183fecb0&gt;,...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.107367</td>\n",
       "      <td>2</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.156097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time param_activation param_hidden_layer_sizes  param_learning_rate_init  param_max_iters  param_temperature                                             params  split0_test_score  split1_test_score  split2_test_score  split3_test_score  split4_test_score  mean_test_score  std_test_score  rank_test_score  split0_train_score  split1_train_score  split2_train_score  split3_train_score  split4_train_score  mean_train_score  std_train_score\n",
       "0           0       0.219400      0.019950         0.002129        0.001929             relu                   [3, 3]                     0.001              100                 10  {'activation': <function relu at 0x1183fecb0>,...           0.541667           0.375000           0.416667           0.291667           0.291667         0.383333        0.092796                3            0.437500            0.416667            0.281250            0.312500            0.156250          0.320833         0.101508\n",
       "1           1       0.873508      0.054728         0.000996        0.000039             relu                   [3, 3]                     0.001              400                 10  {'activation': <function relu at 0x1183fecb0>,...           0.333333           0.541667           0.458333           0.583333           0.208333         0.425000        0.137941                1            0.312500            0.593750            0.510417            0.656250            0.333333          0.481250         0.137468\n",
       "2           2       1.800541      0.095453         0.001033        0.000056             relu                   [3, 3]                     0.001              900                 10  {'activation': <function relu at 0x1183fecb0>,...           0.250000           0.041667           0.375000           0.375000           0.208333         0.250000        0.123603                4            0.302083            0.062500            0.187500            0.458333            0.333333          0.268750         0.134436\n",
       "3           3       2.011549      0.048112         0.001161        0.000026             relu                   [3, 3]                     0.001             1000                 10  {'activation': <function relu at 0x1183fecb0>,...           0.416667           0.208333           0.416667           0.375000           0.541667         0.391667        0.107367                2            0.395833            0.104167            0.281250            0.364583            0.583333          0.345833         0.156097"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/iters/nngs_sa__iters__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>param_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>55.018495</td>\n",
       "      <td>21.108112</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.167912</td>\n",
       "      <td>7</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.122474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>89.552899</td>\n",
       "      <td>69.630977</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>512</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.125934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60.737920</td>\n",
       "      <td>20.698334</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1024</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.125934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60.692780</td>\n",
       "      <td>21.143363</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2048</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.125934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60.913061</td>\n",
       "      <td>21.268937</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4096</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.125934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>59.857552</td>\n",
       "      <td>21.171970</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8192</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.125934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>59.649492</td>\n",
       "      <td>20.751524</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>relu</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16384</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>0.125934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0      55.018495     21.108112         0.001178        0.000365   \n",
       "1           1      89.552899     69.630977         0.001006        0.000015   \n",
       "2           2      60.737920     20.698334         0.001020        0.000108   \n",
       "3           3      60.692780     21.143363         0.001097        0.000065   \n",
       "4           4      60.913061     21.268937         0.001125        0.000187   \n",
       "5           5      59.857552     21.171970         0.000984        0.000075   \n",
       "6           6      59.649492     20.751524         0.001121        0.000217   \n",
       "\n",
       "  param_activation param_hidden_layer_sizes  param_learning_rate_init  \\\n",
       "0             relu                   [3, 3]                     0.001   \n",
       "1             relu                   [3, 3]                     0.001   \n",
       "2             relu                   [3, 3]                     0.001   \n",
       "3             relu                   [3, 3]                     0.001   \n",
       "4             relu                   [3, 3]                     0.001   \n",
       "5             relu                   [3, 3]                     0.001   \n",
       "6             relu                   [3, 3]                     0.001   \n",
       "\n",
       "   param_max_iters  param_temperature  ... mean_test_score  std_test_score  \\\n",
       "0              256                 10  ...        0.816667        0.167912   \n",
       "1              512                 10  ...        0.833333        0.172804   \n",
       "2             1024                 10  ...        0.833333        0.172804   \n",
       "3             2048                 10  ...        0.833333        0.172804   \n",
       "4             4096                 10  ...        0.833333        0.172804   \n",
       "5             8192                 10  ...        0.833333        0.172804   \n",
       "6            16384                 10  ...        0.833333        0.172804   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.947917             0.84375   \n",
       "1                1            0.979167             0.93750   \n",
       "2                1            0.979167             0.93750   \n",
       "3                1            0.979167             0.93750   \n",
       "4                1            0.979167             0.93750   \n",
       "5                1            0.979167             0.93750   \n",
       "6                1            0.979167             0.93750   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.947917             0.65625                 1.0   \n",
       "1            0.947917             0.65625                 1.0   \n",
       "2            0.947917             0.65625                 1.0   \n",
       "3            0.947917             0.65625                 1.0   \n",
       "4            0.947917             0.65625                 1.0   \n",
       "5            0.947917             0.65625                 1.0   \n",
       "6            0.947917             0.65625                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.879167         0.122474  \n",
       "1          0.904167         0.125934  \n",
       "2          0.904167         0.125934  \n",
       "3          0.904167         0.125934  \n",
       "4          0.904167         0.125934  \n",
       "5          0.904167         0.125934  \n",
       "6          0.904167         0.125934  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('out/sa/iters/nngs_ga__iters__cv_results_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seaborn 2\n"
     ]
    }
   ],
   "source": [
    "print ('seaborn', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nist\n"
     ]
    }
   ],
   "source": [
    "if 'loss' not in pd.DataFrame().columns:\n",
    "    pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_iters</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>1.501974e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_iters': 1}</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.246926</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.233408</td>\n",
       "      <td>1.208678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088791</td>\n",
       "      <td>0.012036</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>3.769327e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_iters': 50}</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>1.792806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164846</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>9.602742e-07</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_iters': 100}</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.065617</td>\n",
       "      <td>1.136430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342257</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>1.069229e-04</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_iters': 200}</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.092045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.966997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.724949</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>9.873204e-06</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_iters': 400}</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.184089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.159535</td>\n",
       "      <td>1.209134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.403891</td>\n",
       "      <td>0.056973</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>3.505825e-06</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_iters': 800}</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.112423</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>1.120946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_max_iters              params  split0_test_score  split1_test_score  split2_test_score  mean_test_score  std_test_score  rank_test_score  split0_train_score  split1_train_score  split2_train_score  mean_train_score  std_train_score      loss\n",
       "0       0.002648      0.000121         0.000767    1.501974e-05                1    {'max_iters': 1}              0.575              0.125              0.000         0.233333        0.246926                1              0.5375              0.1000              0.0000          0.212500         0.233408  1.208678\n",
       "1       0.088791      0.012036         0.000805    3.769327e-05               50   {'max_iters': 50}              0.150              0.225              0.200         0.191667        0.031180                1              0.1000              0.4000              0.3625          0.287500         0.133463  1.792806\n",
       "2       0.164846      0.003399         0.000779    9.602742e-07              100  {'max_iters': 100}              0.375              0.400              0.425         0.400000        0.020412                1              0.4125              0.2625              0.3875          0.354167         0.065617  1.136430\n",
       "3       0.342257      0.009534         0.000857    1.069229e-04              200  {'max_iters': 200}              0.325              0.450              0.225         0.333333        0.092045                1              0.4000              0.4500              0.3875          0.412500         0.027003  0.966997\n",
       "4       0.724949      0.014554         0.000806    9.873204e-06              400  {'max_iters': 400}              0.575              0.375              0.125         0.358333        0.184089                1              0.5125              0.3625              0.1250          0.333333         0.159535  1.209134\n",
       "5       1.403891      0.056973         0.000776    3.505825e-06              800  {'max_iters': 800}              0.500              0.375              0.650         0.508333        0.112423                1              0.3750              0.3625              0.4625          0.400000         0.044488  1.120946"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.read_csv('out/nn_simulated_annealing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_csv('out/nn_random_hill_climb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "df = pd.read_csv('out/nn_gradient_descent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.303293</td>\n",
       "      <td>0.322156</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>1.238617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.535629</td>\n",
       "      <td>0.546108</td>\n",
       "      <td>0.337842</td>\n",
       "      <td>0.280640</td>\n",
       "      <td>0.995155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.634731</td>\n",
       "      <td>0.617964</td>\n",
       "      <td>0.407797</td>\n",
       "      <td>0.534612</td>\n",
       "      <td>0.959342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.664072</td>\n",
       "      <td>0.663473</td>\n",
       "      <td>0.411485</td>\n",
       "      <td>1.014783</td>\n",
       "      <td>0.981937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.365569</td>\n",
       "      <td>0.366467</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.551750</td>\n",
       "      <td>1.156262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.020359</td>\n",
       "      <td>0.018081</td>\n",
       "      <td>4.166138</td>\n",
       "      <td>1.657927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>8.420383</td>\n",
       "      <td>1.965178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.650299</td>\n",
       "      <td>0.640719</td>\n",
       "      <td>0.422585</td>\n",
       "      <td>16.525613</td>\n",
       "      <td>0.965727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_accuracy  test_accuracy   test_f1   fit_time      loss\n",
       "0     1        0.303293       0.322156  0.215400   0.008363  1.238617\n",
       "1    50        0.535629       0.546108  0.337842   0.280640  0.995155\n",
       "2   100        0.634731       0.617964  0.407797   0.534612  0.959342\n",
       "3   200        0.664072       0.663473  0.411485   1.014783  0.981937\n",
       "4   400        0.365569       0.366467  0.203100   0.551750  1.156262\n",
       "5   800        0.018862       0.020359  0.018081   4.166138  1.657927\n",
       "6  1600        0.009281       0.007186  0.005185   8.420383  1.965178\n",
       "7  3200        0.650299       0.640719  0.422585  16.525613  0.965727"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1d5c7518>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df['iter'], df['train_accuracy'], 'x-', color=\"r\",\n",
    "         label=\"Train\")\n",
    "plt.plot(df['iter'], df['test_accuracy'], '+-', color=\"g\",\n",
    "         label=\"Test\")\n",
    "plt.plot(df['iter'], df['test_f1'], '+-', color=\"g\",\n",
    "         label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>2.156945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.304607</td>\n",
       "      <td>1.025660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.231546</td>\n",
       "      <td>0.507911</td>\n",
       "      <td>1.327879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.604040</td>\n",
       "      <td>1.023597</td>\n",
       "      <td>1.100059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.019111</td>\n",
       "      <td>0.961140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.877440</td>\n",
       "      <td>0.958478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>8.151575</td>\n",
       "      <td>0.656874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>16.131205</td>\n",
       "      <td>0.469261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_accuracy  test_accuracy   test_f1   fit_time      loss\n",
       "0     1        0.025000       0.066667  0.043011   0.008745  2.156945\n",
       "1    50        0.133333       0.200000  0.139706   0.304607  1.025660\n",
       "2   100        0.358333       0.366667  0.231546   0.507911  1.327879\n",
       "3   200        0.458333       0.600000  0.604040   1.023597  1.100059\n",
       "4   400        0.666667       0.666667  0.555556   2.019111  0.961140\n",
       "5   800        0.333333       0.333333  0.166667   3.877440  0.958478\n",
       "6  1600        0.658333       0.666667  0.534188   8.151575  0.656874\n",
       "7  3200        0.741667       0.800000  0.780220  16.131205  0.469261"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import mlrose\n",
    "import pandas as pd\n",
    "import traitlets.utils.bunch\n",
    "from mlrose import NNGSRunner\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_abalone_ternary():\n",
    "    df = pd.read_csv('data/abalone.data', names=[\"Sex\", \"Length\", \"Diameter\", \"Height\",\n",
    "                                                 \"Whole weight\", \"Shucked weight\", \"Viscera weight\",\n",
    "                                                 \"Shell weight\", \"Rings\"])\n",
    "    df = df[(df[\"Height\"] != 1.13) & (df['Height'] != 0.515)]\n",
    "\n",
    "    # deal with categorical data\n",
    "    df.loc[df.Sex == 'M', 'Male'] = 1.\n",
    "    df.loc[df.Sex == 'F', 'Female'] = 1.\n",
    "    df.loc[df.Sex == 'I', 'Infant'] = 1.\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # bucketize rings\n",
    "    df.loc[df.Rings < 11, 'Rings'] = 1.\n",
    "    df.loc[(df.Rings < 21) & (df.Rings > 10), 'Rings'] = 2.\n",
    "    df.loc[df.Rings > 20, 'Rings'] = 3.\n",
    "\n",
    "    return traitlets.Bunch(\n",
    "        data=df[['Male', 'Female', 'Infant', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight',\n",
    "                 'Viscera weight', 'Shell weight']].values,\n",
    "        target=df[['Rings']].values,\n",
    "        target_names=df[\"Rings\"].unique(),\n",
    "        DESCR='abalone dataset...',\n",
    "        feature_names=['Male', 'Female', 'Infant', \"Length\", \"Diameter\", \"Height\",\n",
    "                       \"Whole weight\", \"Shucked weight\", \"Viscera weight\",\n",
    "                       \"Shell weight\"],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "data = process_abalone_ternary()\n",
    "# Split data into training and test sets\n",
    "#data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, \\\n",
    "                                                    test_size = 0.2, random_state = 3)\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(activation='relu', algorithm='random_hill_climb', bias=True,\n",
       "              clip_max=5, curve=False, early_stopping=True, hidden_nodes=[10],\n",
       "              is_classifier=True, learning_rate=0.1, max_attempts=100,\n",
       "              max_iters=400, mutation_prob=0.1, pop_size=200, random_state=3,\n",
       "              restarts=0,\n",
       "              schedule=GeomDecay(init_temp=1.0, decay=0.99, min_temp=0.001))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize neural network object and fit object\n",
    "nn_model1 = mlrose.NeuralNetwork(hidden_nodes = [10], activation = 'relu', \\\n",
    "                                 algorithm = 'random_hill_climb', max_iters = 400, \\\n",
    "                                 bias = True, is_classifier = True, learning_rate = 0.1, \\\n",
    "                                 early_stopping = True, clip_max = 5, max_attempts = 100, \\\n",
    "                                 random_state = 3)\n",
    "\n",
    "nn_model1.fit(X_train_scaled, y_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6751497005988024\n",
      "0.6694610778443114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "\n",
    "y_train_pred = nn_model1.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = nn_model1.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "print(y_test_accuracy)\n",
    "\n",
    "nn_model1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6520958083832336\n",
      "0.6586826347305389\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "#data = load_iris()\n",
    "data = process_abalone_ternary()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, \\\n",
    "                                                    test_size = 0.2, random_state = 3)\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()\n",
    "# Initialize neural network object and fit object\n",
    "clf = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \\\n",
    "                                 algorithm = 'gradient_descent', max_iters = 1000, \\\n",
    "                                 bias = True, is_classifier = True, learning_rate = 0.0001, \\\n",
    "                                 early_stopping = False, clip_max = 5, max_attempts = 100\n",
    "                           , schedule = mlrose.GeomDecay(init_temp=1))\n",
    "\n",
    "clf.fit(X_train_scaled, y_train_hot)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = clf.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(y_train_accuracy)\n",
    "\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "\n",
    "print(y_test_accuracy)\n",
    "del clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_abalone_ternary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, \\\n",
    "                                                    test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.203983</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>1.499112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.388323</td>\n",
       "      <td>0.389222</td>\n",
       "      <td>0.230967</td>\n",
       "      <td>0.180834</td>\n",
       "      <td>1.236062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.265318</td>\n",
       "      <td>0.375462</td>\n",
       "      <td>0.982175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.656287</td>\n",
       "      <td>0.264543</td>\n",
       "      <td>0.755089</td>\n",
       "      <td>0.785824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.675150</td>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>1.429624</td>\n",
       "      <td>0.628498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.423866</td>\n",
       "      <td>2.825678</td>\n",
       "      <td>0.571480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.731138</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.428567</td>\n",
       "      <td>5.392793</td>\n",
       "      <td>0.544170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.756287</td>\n",
       "      <td>0.734132</td>\n",
       "      <td>0.455382</td>\n",
       "      <td>10.280171</td>\n",
       "      <td>0.506102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_accuracy  test_accuracy   test_f1   fit_time      loss\n",
       "0     1        0.293413       0.293413  0.203983   0.005969  1.499112\n",
       "1    50        0.388323       0.389222  0.230967   0.180834  1.236062\n",
       "2   100        0.550000       0.556886  0.265318   0.375462  0.982175\n",
       "3   200        0.649701       0.656287  0.264543   0.755089  0.785824\n",
       "4   400        0.675150       0.669461  0.299107   1.429624  0.628498\n",
       "5   800        0.710778       0.700599  0.423866   2.825678  0.571480\n",
       "6  1600        0.731138       0.700599  0.428567   5.392793  0.544170\n",
       "7  3200        0.756287       0.734132  0.455382  10.280171  0.506102"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.read_csv('out/nn_simulated_annealing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.203983</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>1.499112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.388323</td>\n",
       "      <td>0.389222</td>\n",
       "      <td>0.230967</td>\n",
       "      <td>0.179471</td>\n",
       "      <td>1.236062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.265318</td>\n",
       "      <td>0.393912</td>\n",
       "      <td>0.982175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.656287</td>\n",
       "      <td>0.264543</td>\n",
       "      <td>0.709686</td>\n",
       "      <td>0.785824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.675150</td>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>1.410153</td>\n",
       "      <td>0.628498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.423866</td>\n",
       "      <td>2.755319</td>\n",
       "      <td>0.571480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.731138</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.428567</td>\n",
       "      <td>5.246664</td>\n",
       "      <td>0.544170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.756287</td>\n",
       "      <td>0.734132</td>\n",
       "      <td>0.455382</td>\n",
       "      <td>10.122840</td>\n",
       "      <td>0.506102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_accuracy  test_accuracy   test_f1   fit_time      loss\n",
       "0     1        0.293413       0.293413  0.203983   0.005990  1.499112\n",
       "1    50        0.388323       0.389222  0.230967   0.179471  1.236062\n",
       "2   100        0.550000       0.556886  0.265318   0.393912  0.982175\n",
       "3   200        0.649701       0.656287  0.264543   0.709686  0.785824\n",
       "4   400        0.675150       0.669461  0.299107   1.410153  0.628498\n",
       "5   800        0.710778       0.700599  0.423866   2.755319  0.571480\n",
       "6  1600        0.731138       0.700599  0.428567   5.246664  0.544170\n",
       "7  3200        0.756287       0.734132  0.455382  10.122840  0.506102"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.read_csv('out/nn_random_hill_climb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.203983</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>1.499112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.388323</td>\n",
       "      <td>0.389222</td>\n",
       "      <td>0.230967</td>\n",
       "      <td>0.200553</td>\n",
       "      <td>1.236062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.265318</td>\n",
       "      <td>0.422154</td>\n",
       "      <td>0.982175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.656287</td>\n",
       "      <td>0.264543</td>\n",
       "      <td>0.794311</td>\n",
       "      <td>0.785824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.675150</td>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>1.533444</td>\n",
       "      <td>0.628498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.423866</td>\n",
       "      <td>3.222161</td>\n",
       "      <td>0.571480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.731138</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.428567</td>\n",
       "      <td>5.510825</td>\n",
       "      <td>0.544170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.756287</td>\n",
       "      <td>0.734132</td>\n",
       "      <td>0.455382</td>\n",
       "      <td>10.461004</td>\n",
       "      <td>0.506102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_accuracy  test_accuracy   test_f1   fit_time      loss\n",
       "0     1        0.293413       0.293413  0.203983   0.006274  1.499112\n",
       "1    50        0.388323       0.389222  0.230967   0.200553  1.236062\n",
       "2   100        0.550000       0.556886  0.265318   0.422154  0.982175\n",
       "3   200        0.649701       0.656287  0.264543   0.794311  0.785824\n",
       "4   400        0.675150       0.669461  0.299107   1.533444  0.628498\n",
       "5   800        0.710778       0.700599  0.423866   3.222161  0.571480\n",
       "6  1600        0.731138       0.700599  0.428567   5.510825  0.544170\n",
       "7  3200        0.756287       0.734132  0.455382  10.461004  0.506102"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.read_csv('out/nn_genetic_alg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>0.203983</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>1.499112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.388323</td>\n",
       "      <td>0.389222</td>\n",
       "      <td>0.230967</td>\n",
       "      <td>0.184796</td>\n",
       "      <td>1.236062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.265318</td>\n",
       "      <td>0.378554</td>\n",
       "      <td>0.982175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.656287</td>\n",
       "      <td>0.264543</td>\n",
       "      <td>0.761045</td>\n",
       "      <td>0.785824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.675150</td>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>1.545120</td>\n",
       "      <td>0.628498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.423866</td>\n",
       "      <td>2.868104</td>\n",
       "      <td>0.571480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.731138</td>\n",
       "      <td>0.700599</td>\n",
       "      <td>0.428567</td>\n",
       "      <td>5.451061</td>\n",
       "      <td>0.544170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3200</td>\n",
       "      <td>0.756287</td>\n",
       "      <td>0.734132</td>\n",
       "      <td>0.455382</td>\n",
       "      <td>10.898844</td>\n",
       "      <td>0.506102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  train_accuracy  test_accuracy   test_f1   fit_time      loss\n",
       "0     1        0.293413       0.293413  0.203983   0.006065  1.499112\n",
       "1    50        0.388323       0.389222  0.230967   0.184796  1.236062\n",
       "2   100        0.550000       0.556886  0.265318   0.378554  0.982175\n",
       "3   200        0.649701       0.656287  0.264543   0.761045  0.785824\n",
       "4   400        0.675150       0.669461  0.299107   1.545120  0.628498\n",
       "5   800        0.710778       0.700599  0.423866   2.868104  0.571480\n",
       "6  1600        0.731138       0.700599  0.428567   5.451061  0.544170\n",
       "7  3200        0.756287       0.734132  0.455382  10.898844  0.506102"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.read_csv('out/nn_gradient_descent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
